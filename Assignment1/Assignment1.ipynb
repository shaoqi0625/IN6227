{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d008740e-6cfc-40bf-8602-cf73fce80d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba232a6-9047-458c-b652-ad33d437aeb8",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70d9775a-04bb-45fc-bed6-39f0942cc0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num','marital-status', 'occupation', 'relationship', 'race', 'gender','capital-gain', 'capital-loss', 'hours-per-week', 'native-country','income']\n",
    "\n",
    "train = pd.read_csv('./Census Income Data Set/Census Income Data Set/adult.data.txt', sep=\",\\s\", header=None, names = column_names, engine = 'python')\n",
    "test = pd.read_csv('./Census Income Data Set/Census Income Data Set/adult.test.txt', sep=\",\\s\", header=None, names = column_names, engine = 'python')\n",
    "test['income'].replace(regex=True,inplace=True,to_replace=r'\\.',value=r'')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425bcfb9-bb60-42a7-abf5-e73a62cbfe0e",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a3b4870-cb5b-4fd8-8332-a91c5755eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.replace('?', pd.NA, inplace=True)\n",
    "train_cleaned = train.dropna(axis=0)\n",
    "\n",
    "test.replace('?', pd.NA, inplace=True)\n",
    "test_cleaned = test.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4dda7fc-907a-4bc2-a7ce-de922ed96078",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30162 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   age              30162 non-null  int64   \n",
      " 1   workclass        30162 non-null  category\n",
      " 2   fnlwgt           30162 non-null  int64   \n",
      " 3   education        30162 non-null  category\n",
      " 4   educational-num  30162 non-null  int64   \n",
      " 5   marital-status   30162 non-null  category\n",
      " 6   occupation       30162 non-null  category\n",
      " 7   relationship     30162 non-null  category\n",
      " 8   race             30162 non-null  category\n",
      " 9   gender           30162 non-null  category\n",
      " 10  capital-gain     30162 non-null  int64   \n",
      " 11  capital-loss     30162 non-null  int64   \n",
      " 12  hours-per-week   30162 non-null  int64   \n",
      " 13  native-country   30162 non-null  category\n",
      " 14  income           30162 non-null  category\n",
      "dtypes: category(9), int64(6)\n",
      "memory usage: 1.9 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15060 entries, 0 to 16280\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   age              15060 non-null  int64   \n",
      " 1   workclass        15060 non-null  category\n",
      " 2   fnlwgt           15060 non-null  int64   \n",
      " 3   education        15060 non-null  category\n",
      " 4   educational-num  15060 non-null  int64   \n",
      " 5   marital-status   15060 non-null  category\n",
      " 6   occupation       15060 non-null  category\n",
      " 7   relationship     15060 non-null  category\n",
      " 8   race             15060 non-null  category\n",
      " 9   gender           15060 non-null  category\n",
      " 10  capital-gain     15060 non-null  int64   \n",
      " 11  capital-loss     15060 non-null  int64   \n",
      " 12  hours-per-week   15060 non-null  int64   \n",
      " 13  native-country   15060 non-null  category\n",
      " 14  income           15060 non-null  category\n",
      "dtypes: category(9), int64(6)\n",
      "memory usage: 960.0 KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86139\\AppData\\Local\\Temp\\ipykernel_3464\\336448181.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_cleaned[col] = train_cleaned[col].astype('category')\n",
      "C:\\Users\\86139\\AppData\\Local\\Temp\\ipykernel_3464\\336448181.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_cleaned[col] = train_cleaned[col].astype('category')\n",
      "C:\\Users\\86139\\AppData\\Local\\Temp\\ipykernel_3464\\336448181.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_cleaned[col] = train_cleaned[col].astype('category')\n",
      "C:\\Users\\86139\\AppData\\Local\\Temp\\ipykernel_3464\\336448181.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_cleaned[col] = train_cleaned[col].astype('category')\n",
      "C:\\Users\\86139\\AppData\\Local\\Temp\\ipykernel_3464\\336448181.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_cleaned[col] = train_cleaned[col].astype('category')\n",
      "C:\\Users\\86139\\AppData\\Local\\Temp\\ipykernel_3464\\336448181.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_cleaned[col] = train_cleaned[col].astype('category')\n",
      "C:\\Users\\86139\\AppData\\Local\\Temp\\ipykernel_3464\\336448181.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_cleaned[col] = train_cleaned[col].astype('category')\n",
      "C:\\Users\\86139\\AppData\\Local\\Temp\\ipykernel_3464\\336448181.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_cleaned[col] = train_cleaned[col].astype('category')\n",
      "C:\\Users\\86139\\AppData\\Local\\Temp\\ipykernel_3464\\336448181.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_cleaned[col] = train_cleaned[col].astype('category')\n",
      "C:\\Users\\86139\\AppData\\Local\\Temp\\ipykernel_3464\\336448181.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_cleaned[col] = test_cleaned[col].astype('category')\n",
      "C:\\Users\\86139\\AppData\\Local\\Temp\\ipykernel_3464\\336448181.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_cleaned[col] = test_cleaned[col].astype('category')\n",
      "C:\\Users\\86139\\AppData\\Local\\Temp\\ipykernel_3464\\336448181.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_cleaned[col] = test_cleaned[col].astype('category')\n",
      "C:\\Users\\86139\\AppData\\Local\\Temp\\ipykernel_3464\\336448181.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_cleaned[col] = test_cleaned[col].astype('category')\n",
      "C:\\Users\\86139\\AppData\\Local\\Temp\\ipykernel_3464\\336448181.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_cleaned[col] = test_cleaned[col].astype('category')\n",
      "C:\\Users\\86139\\AppData\\Local\\Temp\\ipykernel_3464\\336448181.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_cleaned[col] = test_cleaned[col].astype('category')\n",
      "C:\\Users\\86139\\AppData\\Local\\Temp\\ipykernel_3464\\336448181.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_cleaned[col] = test_cleaned[col].astype('category')\n",
      "C:\\Users\\86139\\AppData\\Local\\Temp\\ipykernel_3464\\336448181.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_cleaned[col] = test_cleaned[col].astype('category')\n",
      "C:\\Users\\86139\\AppData\\Local\\Temp\\ipykernel_3464\\336448181.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_cleaned[col] = test_cleaned[col].astype('category')\n"
     ]
    }
   ],
   "source": [
    "# Setting all the categorical columns to type category\n",
    "for col in set(train_cleaned.columns) - set(train_cleaned.describe().columns):\n",
    "    train_cleaned[col] = train_cleaned[col].astype('category')\n",
    "print(train_cleaned.info())\n",
    "\n",
    "# Setting all the categorical columns to type category\n",
    "for col in set(test_cleaned.columns) - set(test_cleaned.describe().columns):\n",
    "    test_cleaned[col] = test_cleaned[col].astype('category')\n",
    "print(test_cleaned.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85258eac-e1d0-4909-bfe0-6041c7240e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15060.000000</td>\n",
       "      <td>1.506000e+04</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.768327</td>\n",
       "      <td>1.896164e+05</td>\n",
       "      <td>10.112749</td>\n",
       "      <td>1120.301594</td>\n",
       "      <td>89.041899</td>\n",
       "      <td>40.951594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.380676</td>\n",
       "      <td>1.056150e+05</td>\n",
       "      <td>2.558727</td>\n",
       "      <td>7703.181842</td>\n",
       "      <td>406.283245</td>\n",
       "      <td>12.062831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.349200e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.166550e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.779550e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.385888e+05</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>3770.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  educational-num  capital-gain  \\\n",
       "count  15060.000000  1.506000e+04     15060.000000  15060.000000   \n",
       "mean      38.768327  1.896164e+05        10.112749   1120.301594   \n",
       "std       13.380676  1.056150e+05         2.558727   7703.181842   \n",
       "min       17.000000  1.349200e+04         1.000000      0.000000   \n",
       "25%       28.000000  1.166550e+05         9.000000      0.000000   \n",
       "50%       37.000000  1.779550e+05        10.000000      0.000000   \n",
       "75%       48.000000  2.385888e+05        13.000000      0.000000   \n",
       "max       90.000000  1.490400e+06        16.000000  99999.000000   \n",
       "\n",
       "       capital-loss  hours-per-week  \n",
       "count  15060.000000    15060.000000  \n",
       "mean      89.041899       40.951594  \n",
       "std      406.283245       12.062831  \n",
       "min        0.000000        1.000000  \n",
       "25%        0.000000       40.000000  \n",
       "50%        0.000000       40.000000  \n",
       "75%        0.000000       45.000000  \n",
       "max     3770.000000       99.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary\n",
    "train_cleaned.describe()\n",
    "test_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52e2766d-f2c1-422c-bfc5-0c2c5b9e1313",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_cleaned.drop(columns = ['income', 'fnlwgt'])\n",
    "train_label = train_cleaned['income']\n",
    "\n",
    "test_data = test_cleaned.drop(columns = ['income', 'fnlwgt'])\n",
    "test_label = test_cleaned['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c910e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "categorical_cols = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
    "numerical_cols = ['age', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "train_data_transformed = pipeline.fit_transform(train_data)\n",
    "test_data_transformed = pipeline.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8acb645",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_transformed_dense = train_data_transformed.toarray()\n",
    "test_data_transformed_dense = test_data_transformed.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f96f861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'<=50K': 0, '>50K': 1}\n",
    "train_label = train_label.map(label_mapping)\n",
    "test_label = test_label.map(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82e3b60-517c-4840-b9ef-61bc1d0e32d3",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e1b77a82-4820-46ee-aa70-ce9bca3b8cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=None, min_samples_leaf=None, alpha = None):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.alpha = alpha\n",
    "        self.tree = None\n",
    "\n",
    "    # Calculating Entropy\n",
    "    def entropy(self, y):\n",
    "        ent = 0.0\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        ent = -np.sum(probabilities * np.log2(probabilities))\n",
    "        return ent\n",
    "\n",
    "    # Splitting Data\n",
    "    def split(self, X, y, feature, threshold):\n",
    "        left_mask = X[:, feature] <= threshold\n",
    "        right_mask = X[:, feature] > threshold\n",
    "        return X[left_mask], X[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    # Calculating Information Gain\n",
    "    def information_gain(self, X, y, feature, threshold):\n",
    "        parent_entropy = self.entropy(y)\n",
    "        X_left, X_right, y_left, y_right = self.split(X, y, feature, threshold)\n",
    "        # if any child node is null, information gain is 0\n",
    "        if len(y_left) == 0 or len(y_right) == 0:\n",
    "            return 0\n",
    "        # weighted entropy\n",
    "        n = len(y)\n",
    "        n_left, n_right = len(y_left), len(y_right)\n",
    "        weighted_entropy = (n_left / n) * self.entropy(y_left) + (n_right / n) * self.entropy(y_right)\n",
    "        information_gaining = parent_entropy - weighted_entropy\n",
    "        return information_gaining\n",
    "\n",
    "    # Best Split\n",
    "    def best_split(self, X, y):\n",
    "        # initialization\n",
    "        best_gain = -1\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        # traversal all features\n",
    "        for feature in range(X.shape[1]):\n",
    "            unique_values = np.unique(X[:, feature])\n",
    "            # one feature -> skip\n",
    "            if len(unique_values) == 1:\n",
    "                continue\n",
    "            # traversal all thresholds\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                gain = self.information_gain(X, y, feature, threshold)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    # Building Tree\n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        # stop condictions\n",
    "        # prediction result\n",
    "        if len(np.unique(y)) == 1:\n",
    "            return y[0]\n",
    "        # max depth\n",
    "        if self.max_depth is not None and depth >= self.max_depth:\n",
    "            return np.bincount(y).argmax()\n",
    "        # min split samples\n",
    "        if len(y) < self.min_samples_split:\n",
    "            return np.bincount(y).argmax()\n",
    "        # best split and shreshold\n",
    "        feature, threshold = self.best_split(X, y)\n",
    "        if feature is None:\n",
    "            return np.bincount(y).argmax()\n",
    "        # split data\n",
    "        X_left, X_right, y_left, y_right = self.split(X, y, feature, threshold)\n",
    "        if len(y_left) < self.min_samples_leaf or len(y_right) < self.min_samples_leaf:\n",
    "            return np.bincount(y).argmax()\n",
    "        # build the subtree recursively\n",
    "        left_subtree = self.build_tree(X_left, y_left, depth + 1)\n",
    "        right_subtree = self.build_tree(X_right, y_right, depth + 1)\n",
    "        return {'feature': feature, 'threshold': threshold, 'left': left_subtree, 'right': right_subtree}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self.build_tree(np.array(X), np.array(y))\n",
    "        self.tree = self.prune_tree(self.tree, np.array(X), np.array(y))\n",
    "\n",
    "    # Prediction\n",
    "    def predict_sample(self, x, tree):\n",
    "        if isinstance(tree, dict):\n",
    "            feature = tree['feature']\n",
    "            threshold = tree['threshold']\n",
    "            if x[feature] <= threshold:\n",
    "                return self.predict_sample(x, tree['left'])\n",
    "            else:\n",
    "                return self.predict_sample(x, tree['right'])\n",
    "        else:\n",
    "            return tree\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self.predict_sample(x, self.tree) for x in X]\n",
    "    \n",
    "    def prune_tree(self, tree, X, y):\n",
    "        # Recursively prune the left and right subtrees\n",
    "        if isinstance(tree, dict):\n",
    "            tree['left'] = self.prune_tree(tree['left'], X, y)\n",
    "            tree['right'] = self.prune_tree(tree['right'], X, y)\n",
    "            # If both left and right subtrees are leaves (not dicts), consider pruning\n",
    "            if not isinstance(tree['left'], dict) and not isinstance(tree['right'], dict):\n",
    "                # Evaluate the cost complexity of pruning this subtree\n",
    "                original_accuracy = self.evaluate_tree(tree, X, y)\n",
    "                pruned_tree = np.bincount(y).argmax()\n",
    "                pruned_accuracy = self.evaluate_tree(pruned_tree, X, y)\n",
    "                if pruned_accuracy - original_accuracy < self.alpha:\n",
    "                    # Prune the tree\n",
    "                    return pruned_tree\n",
    "        return tree\n",
    "\n",
    "    def evaluate_tree(self, tree, X, y):\n",
    "        predictions = [self.predict_sample(x, tree) for x in X]\n",
    "        return np.mean(predictions == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a9a03541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(actual, pred):\n",
    "    \n",
    "    confusion = pd.crosstab(actual, pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "    TP = confusion.loc[1,1]\n",
    "    TN = confusion.loc[0,0]\n",
    "    FP = confusion.loc[0,1]\n",
    "    FN = confusion.loc[1,0]\n",
    "\n",
    "    accuracy = ((TP+TN))/(TP+FN+FP+TN)\n",
    "    precision = (TP)/(TP+FP)\n",
    "    recall = (TP)/(TP+FN)\n",
    "    f1_score = (2*recall*precision)/(recall+precision)\n",
    "    \n",
    "    out = {}\n",
    "    out['accuracy'] =  accuracy\n",
    "    out['precision'] = precision\n",
    "    out['recall'] = recall\n",
    "    out['f1_score'] = f1_score\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6c0ec7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8542496679946879\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTree(max_depth=10, min_samples_split=2, min_samples_leaf=1, alpha = 0.001)\n",
    "tree.fit(train_data_transformed_dense, train_label)\n",
    "predictions = tree.predict(test_data_transformed_dense)\n",
    "acc = np.sum(predictions == test_label) / len(test_label)\n",
    "print(f\"Accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5a2261a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8542496679946879, 'precision': 0.783427495291902, 'recall': 0.5621621621621622, 'f1_score': 0.6546026750590086}\n"
     ]
    }
   ],
   "source": [
    "output = model_eval(test_label, predictions)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9eebf4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'decision_tree.png'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def visualize_tree(node, dot=None):\n",
    "    if dot is None:\n",
    "        dot = Digraph(comment='Decision Tree')\n",
    "\n",
    "    if isinstance(node, dict):\n",
    "        feature = node['feature']\n",
    "        threshold = node['threshold']\n",
    "        label = f'Feature {feature} <= {threshold}'\n",
    "        dot.node(str(id(node)), label=label)\n",
    "        \n",
    "        if 'left' in node:\n",
    "            left_child = node['left']\n",
    "            dot.edge(str(id(node)), str(id(left_child)), label='True')\n",
    "            visualize_tree(left_child, dot)\n",
    "        \n",
    "        if 'right' in node:\n",
    "            right_child = node['right']\n",
    "            dot.edge(str(id(node)), str(id(right_child)), label='False')\n",
    "            visualize_tree(right_child, dot)\n",
    "    else:\n",
    "        dot.node(str(id(node)), label=f'Value: {node}', shape='ellipse')\n",
    "    \n",
    "    return dot\n",
    "\n",
    "dot = visualize_tree(tree.tree)\n",
    "\n",
    "dot.render('decision_tree', format='png', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26e02657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8116865869853918"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Just For Comparison\n",
    "## from sklearn.tree import DecisionTreeClassifier\n",
    "## tree_compare = DecisionTreeClassifier()\n",
    "## tree_compare.fit(train_data_transformed_dense, train_label)\n",
    "## tree_compare.score(test_data_transformed_dense, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e1cf66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
